	Basically, Monte Carlo localization is a type of particle filter localization algorithm that finds the position of a robot. Note that this algorithm requires a known map of the system to work, with may be a slight problem in our case. Monte Carlo starts with an uniform distribution of particles around the whole map. When it receives sensor information, it updates the particles based on what positions it is likely to be in. When the robot moves again, it moves the particles with it the same distance. However, there is some uncertainty applied as we don’t know if the robot actually moved the distance it thought it moves. It continuously resamples and redistributes the particles until there is a group of particles (hopefully) with the highest density, which indicates its current position. Note that the particle resampling is from recursive Bayesian estimation, through using the states of the previous particles. This type of sampling is a way to sampling by estimating an unknown probability function.
	Monte Carlo has been criticized, even on the paper in the year it was used as the main modeling algorithm. Quoting, “Since there are too many observations to process at once, modeling prunes some unreasonable hypotheses with a criterion of the integral of the probability density function. This solution was found to be the better solution compared to particle filters, which would be to either too slow or too inaccurate, and Kalman filter variants (e.g., Unscented Kalman Filter and Extended Kalman Filter), which would not be able to account for bad observations without an inaccurate, hard-coded error rejection filter.” However, in my personal opinion this is better than randomly guessing a gaussian distribution works. This disparity on the journal paper is most likely due to the fact that Monte Carlo Localization was coded after the journal paper was made (2 weeks before competition).